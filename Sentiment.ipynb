{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ff3389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/shrutikorada/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shrutikorada/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import geopandas as gp\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18d62e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eff3c1",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55fd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove @user\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i,'',input_txt)\n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b840fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional cleaning\n",
    "tweets['Tweet'] = np.vectorize(remove_pattern)(tweets['text'], '@[\\w]*') # create new column with removed @user\n",
    "tweets['Tweet'] = tweets['Tweet'].apply(lambda x: re.split('http:\\/\\/.*', str(x))[0]) # remove urls\n",
    "tweets['Tweet'] = tweets['Tweet'].str.replace('[^a-zA-Z#]+',' ') # remove special characters, numbers, punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8a692bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function that takes care of all the preprocessing stuff.\n",
    "def preprocess():\n",
    "\n",
    "    tweets['Tweet'] = tweets['Tweet'].str.lower() # Ensuring all words in the Tweet column of training data are lowercased\n",
    "\n",
    "  # Parsing the stop_words.txt file and storing all the words in a list.\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "  # Removing all stopwords from all the tweets in training data.\n",
    "    tweets[\"Tweet\"] = tweets[\"Tweet\"].apply(lambda func: ' '.join(sw \n",
    "                                            for sw in func.split() \n",
    "                                            if sw not in stopwords))\n",
    "  #Training Data\n",
    "    tweets['Tweet'] = tweets['Tweet'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '') # Removing hyperlinks from all the tweets\n",
    "    tweets['Tweet'] = tweets['Tweet'].str.replace('@[A-Za-z0-9]+', '') # Removing usernames from all the tweets.\n",
    "    tweets['Tweet'] = tweets['Tweet'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '') # Removing hashtags, including the text, from all the tweets\n",
    "    tweets['Tweet'] = tweets['Tweet'].str.replace('\\d+', '') # Removing numbers from all the tweets\n",
    "\n",
    "    special_chars = [\"!\",'\"',\"%\",\"&\",\"amp\",\"'\",\"(\",\")\", \"*\",\"+\",\",\",\"-\",\".\",\n",
    "                  \"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "                  \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\",\"@\",\"#\",\"$\"]\n",
    "\n",
    "    for c in special_chars:\n",
    "        tweets['Tweet'] = tweets['Tweet'].str.replace(c,'') # Removing all special characters from all the tweets\n",
    "\n",
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60e6fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create new variable tokenized tweet \n",
    "tokenized_tweet = tweets['Tweet'].apply(lambda x: x.split())\n",
    "\n",
    "# remove stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "tokenized_tweet = [w for w in tokenized_tweet if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584862fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tokens into one sentence\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "    \n",
    "# change df['Tweet'] to tokenized_tweet\n",
    "tweets['Tweet']  = tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81c9c2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     said\n",
       "1                  plus added commercials experience tacky\n",
       "2                   today must mean need take another trip\n",
       "3        really aggressive blast obnoxious entertainmen...\n",
       "4                                     really big bad thing\n",
       "                               ...                        \n",
       "14635                   thank got different flight chicago\n",
       "14636    leaving minutes late flight warnings communica...\n",
       "14637                      please bring american airlines \n",
       "14638    money change flight answer phones suggestions ...\n",
       "14639    ppl need know many seats next flight plz put u...\n",
       "Name: Tweet, Length: 14640, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweets after cleaning\n",
    "tweets['Tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294ca8d",
   "metadata": {},
   "source": [
    "## Deriving sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9f7e515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.236, 'neu': 0.628, 'pos': 0.135, 'compound': -0.2716}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what the output of sentiment scoring looks like\n",
    "sia.polarity_scores(\"it's really aggressive to blast obnoxious entertainment in your guests' faces &amp; they have little recourse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bf3d968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assign sentiment scores\n",
    "scores = []\n",
    "for tweet in tweets['Tweet']:\n",
    "    score = sia.polarity_scores(tweet)\n",
    "    scores.append(score['compound'])\n",
    "tweets['sentiment_scores'] = scores\n",
    "tweets['sentiment_derived'] = [\"positive\" if w >0 else \"negative\" if w < 0 else \"neutral\" for w in tweets['sentiment_scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e67f2b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0000\n",
       "1        0.0000\n",
       "2        0.0000\n",
       "3       -0.3306\n",
       "4       -0.5829\n",
       "          ...  \n",
       "14635    0.3612\n",
       "14636   -0.7003\n",
       "14637    0.3182\n",
       "14638    0.3818\n",
       "14639    0.0772\n",
       "Name: sentiment_scores, Length: 14640, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['sentiment_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "747a725b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5006147540983606"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent match between assigned and derived sentiment\n",
    "tweets['match'] = (tweets['sentiment_derived']==tweets['airline_sentiment']).astype(int)\n",
    "tweets[['airline_sentiment','sentiment_derived','match']]\n",
    "tweets['match'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b36fb",
   "metadata": {},
   "source": [
    "About 50% of the derived sentiment scores match the original scores. Additional pre-processing required. Most of the errors are negative or neutral tweets that are misclassified as neutral or positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b6050db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment_derived</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>3920</td>\n",
       "      <td>1986</td>\n",
       "      <td>3272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>366</td>\n",
       "      <td>1347</td>\n",
       "      <td>1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>77</td>\n",
       "      <td>224</td>\n",
       "      <td>2062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment_derived  negative  neutral  positive\n",
       "airline_sentiment                             \n",
       "negative               3920     1986      3272\n",
       "neutral                 366     1347      1386\n",
       "positive                 77      224      2062"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crosstab of assigned vs derived sentiment\n",
    "pd.crosstab(tweets.airline_sentiment, tweets.sentiment_derived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10b41d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.625, subjectivity=0.6)\n",
      "Sentiment(classification='pos', p_pos=0.523148148148148, p_neg=0.4768518518518517)\n"
     ]
    }
   ],
   "source": [
    "blobber = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "blob = TextBlob(\"i love it!\")\n",
    "print(blob.sentiment)\n",
    "\n",
    "blob = blobber(\"i hate it!\")\n",
    "print(blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0266634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for tweet in tweets['Tweet']:\n",
    "    score = TextBlob(tweet)\n",
    "    scores.append(score.sentiment[0])\n",
    "tweets['textblob_scores'] = scores\n",
    "tweets['textblob_derived'] = [\"positive\" if w >0 else \"negative\" if w < 0 else \"neutral\" for w in tweets['textblob_scores']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40f475fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>textblob_derived</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment_derived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>2218</td>\n",
       "      <td>1435</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>374</td>\n",
       "      <td>2519</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>652</td>\n",
       "      <td>2041</td>\n",
       "      <td>4027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "textblob_derived   negative  neutral  positive\n",
       "sentiment_derived                             \n",
       "negative               2218     1435       710\n",
       "neutral                 374     2519       664\n",
       "positive                652     2041      4027"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(tweets.airline_sentiment, tweets.textblob_derived)\n",
    "pd.crosstab(tweets.sentiment_derived, tweets.textblob_derived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8a6bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eaec822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_sentiment(tweets):\n",
    "    if (tweets['textblob_derived'] == 'negative') or (tweets['sentiment_derived'] == 'negative'):\n",
    "        return 'negative'\n",
    "    if (tweets['textblob_derived'] == 'neutral') and (tweets['sentiment_derived'] == 'positive'):\n",
    "        return 'neutral'\n",
    "    if (tweets['textblob_derived'] == 'positive') and (tweets['sentiment_derived'] == 'neutral'):\n",
    "        return 'neutral'\n",
    "    if (tweets['textblob_derived'] == 'neutral') and (tweets['sentiment_derived'] == 'neutral'):\n",
    "        return 'negative'\n",
    "    if (tweets['textblob_derived'] == 'positive') and (tweets['sentiment_derived'] == 'positive'):\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34a9ccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['final_derived'] = tweets.apply(combined_sentiment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ac9159a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_derived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4722</td>\n",
       "      <td>515</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2790</td>\n",
       "      <td>1886</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1666</td>\n",
       "      <td>698</td>\n",
       "      <td>1663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "airline_sentiment  negative  neutral  positive\n",
       "final_derived                                 \n",
       "negative               4722      515       152\n",
       "neutral                2790     1886       548\n",
       "positive               1666      698      1663"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(tweets.final_derived, tweets.airline_sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
